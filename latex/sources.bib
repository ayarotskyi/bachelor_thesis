% This file was created with JabRef 2.10b2.
% Encoding: UTF-8

@misc{neu2012apprenticeshiplearningusinginverse,
  title         = {Apprenticeship Learning using Inverse Reinforcement Learning and Gradient Methods},
  author        = {Gergely Neu and Csaba Szepesvari},
  year          = {2012},
  eprint        = {1206.5264},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1206.5264}
}

@misc{lee2021approximateinversereinforcementlearning,
  title         = {Approximate Inverse Reinforcement Learning from Vision-based Imitation Learning},
  author        = {Keuntaek Lee and Bogdan Vlahov and Jason Gibson and James M. Rehg and Evangelos A. Theodorou},
  year          = {2021},
  eprint        = {2004.08051},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/2004.08051}
}

@inproceedings{ng2000algorithms,
  title     = {Algorithms for inverse reinforcement learning.},
  author    = {Ng, Andrew Y and Russell, Stuart and others},
  booktitle = {Icml},
  volume    = {1},
  number    = {2},
  pages     = {2},
  year      = {2000}
}

@inproceedings{8855753,
  author    = {Farag, Wael and Saleh, Zakaria},
  booktitle = {2018 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)},
  title     = {Behavior Cloning for Autonomous Driving using Convolutional Neural Networks},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1-7},
  keywords  = {Training;Convolution;Automobiles;Training data;Cameras;Computer architecture;Cloning;Behavioral Cloning;Convolutional Neural Network;Autonomous Driving;Machine Learning},
  doi       = {10.1109/3ICT.2018.8855753}
}

@article{10.1145/3054912,
  author     = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  title      = {Imitation Learning: A Survey of Learning Methods},
  year       = {2017},
  issue_date = {March 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {50},
  number     = {2},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3054912},
  doi        = {10.1145/3054912},
  month      = apr,
  articleno  = {21},
  numpages   = {35},
  keywords   = {Imitation learning, deep learning, feature representations, intelligent agents, learning from demonstrations, learning from experience, reinforcement learning, robotics, self-improvement}
}

@misc{pan2019agileautonomousdrivingusing,
  title         = {Agile Autonomous Driving using End-to-End Deep Imitation Learning},
  author        = {Yunpeng Pan and Ching-An Cheng and Kamil Saigol and Keuntaek Lee and Xinyan Yan and Evangelos Theodorou and Byron Boots},
  year          = {2019},
  eprint        = {1709.07174},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/1709.07174}
}

@misc{bojarski2016endendlearningselfdriving,
  title         = {End to End Learning for Self-Driving Cars},
  author        = {Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D. Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba},
  year          = {2016},
  eprint        = {1604.07316},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1604.07316}
}

@inproceedings{5152385,
  author    = {Pastor, Peter and Hoffmann, Heiko and Asfour, Tamim and Schaal, Stefan},
  booktitle = {2009 IEEE International Conference on Robotics and Automation},
  title     = {Learning and generalization of motor skills by learning from demonstration},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {763-768},
  keywords  = {Robots;Differential equations;Libraries;Humans;Grippers;Fingers;Robustness;Robotics and automation;Labeling;Anthropomorphism},
  doi       = {10.1109/ROBOT.2009.5152385}
}

@misc{geyer2020a2d2audiautonomousdriving,
  title         = {A2D2: Audi Autonomous Driving Dataset},
  author        = {Jakob Geyer and Yohannes Kassahun and Mentar Mahmudi and Xavier Ricou and Rupesh Durgesh and Andrew S. Chung and Lorenz Hauswald and Viet Hoang Pham and Maximilian Mühlegg and Sebastian Dorn and Tiffany Fernandez and Martin Jänicke and Sudesh Mirashi and Chiragkumar Savani and Martin Sturm and Oleksandr Vorobiov and Martin Oelker and Sebastian Garreis and Peter Schuberth},
  year          = {2020},
  eprint        = {2004.06320},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2004.06320}
}

@misc{drews2017aggressivedeepdrivingmodel,
  title         = {Aggressive Deep Driving: Model Predictive Control with a CNN Cost Model},
  author        = {Paul Drews and Grady Williams and Brian Goldfain and Evangelos A. Theodorou and James M. Rehg},
  year          = {2017},
  eprint        = {1707.05303},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/1707.05303}
}

@article{ARGALL2009469,
  title    = {A survey of robot learning from demonstration},
  journal  = {Robotics and Autonomous Systems},
  volume   = {57},
  number   = {5},
  pages    = {469-483},
  year     = {2009},
  issn     = {0921-8890},
  doi      = {https://doi.org/10.1016/j.robot.2008.10.024},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889008001772},
  author   = {Brenna D. Argall and Sonia Chernova and Manuela Veloso and Brett Browning},
  keywords = {Learning from demonstration, Robotics, Machine learning, Autonomous systems},
  abstract = {We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research.}
}